name: gilgoblin

services:
  gilgoblin-database:
    image: nickreinlein/gilgoblin-database
    container_name: database
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PGUSER: ${PGUSER}
      PGDATA: ${PGDATA}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - gilgoblin
    ports:
      - "5432:${PORT_DATABASE}"
    logging:
      driver: 'json-file'
      options:
        max-size: '50m'
    volumes:
      - ./src/Database/db:/var/lib/postgresql/data
      - ./src/Database/scripts:/docker-entrypoint-initdb.d
    restart: unless-stopped

  gilgoblin-api:
    image: nickreinlein/gilgoblin-api
    container_name: api
    depends_on:
      - gilgoblin-database
    environment:
      ConnectionStrings__GilGoblinDbContext: ${DB_CONNECTION_STRING}
    healthcheck:
      test: [ "CMD-SHELL" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - gilgoblin
    ports:
      - "${PORT_API}:8080"
    logging:
      driver: 'json-file'
      options:
        max-size: '50m'
    restart: unless-stopped

  gilgoblin-dataupdater:
    # image: nickreinlein/gilgoblin-dataupdater
    # container_name: dataupdater
    image: accountant
    build: src/Accountant/
    depends_on:
      - gilgoblin-database
      - gilgoblin-api
    environment:
      ConnectionStrings__GilGoblinDbContext: ${DB_CONNECTION_STRING}
    healthcheck:
      test: [ "CMD-SHELL" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - gilgoblin
    logging:
      driver: 'json-file'
      options:
        max-size: '50m'
    restart: unless-stopped

  gilgoblin-accountant:
    # image: nickreinlein/gilgoblin-accountant
    # container_name: accountant
    image: accountant
    build: src/Accountant/
    depends_on:
      - gilgoblin-database
      - gilgoblin-api
    environment:
      ConnectionStrings__GilGoblinDbContext: ${DB_CONNECTION_STRING}
    healthcheck:
      test: [ "CMD-SHELL" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - gilgoblin
    logging:
      driver: 'json-file'
      options:
        max-size: '50m'
    restart: unless-stopped

  gilgoblin-frontend:
    image: nickreinlein/gilgoblin-frontend
    container_name: frontend
    ## For local testing, replace with:
    # image: frontend
    # build: src/frontend/
    depends_on:
      - gilgoblin-database
      - gilgoblin-api
    healthcheck:
      test: [ "CMD-SHELL" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - gilgoblin
    ports:
      - "3000:${PORT_FRONTEND}"
    logging:
      driver: 'json-file'
      options:
        max-size: '50m'
    restart: unless-stopped

  ### Alerts & Monitoring ###

  gilgoblin-influxdb:
    image: influxdb:1.8.10
    container_name: influxdb
    logging:
      driver: 'json-file'
      options:
        max-size: '50m'
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=${DOCKER_INFLUXDB_INIT_MODE}
      - DOCKER_INFLUXDB_INIT_ORG=${DOCKER_INFLUXDB_INIT_ORG}
      - DOCKER_INFLUXDB_INIT_BUCKET=${DOCKER_INFLUXDB_INIT_BUCKET}
      - DOCKER_INFLUXDB_DB=${DOCKER_INFLUXDB_DB}
      - DOCKER_INFLUXDB_ADMIN_USER=${DOCKER_INFLUXDB_ADMIN_USER}
      - DOCKER_INFLUXDB_ADMIN_PASSWORD=${DOCKER_INFLUXDB_ADMIN_PASSWORD}
    networks:
      - gilgoblin
    ports:
      - '8086:8086'
    volumes:
      - ./benchmarks/influxdb:/var/lib/influxdb

  gilgoblin-prometheus:
    image: prom/prometheus
    container_name: prometheus
    command:
      - --web.enable-remote-write-receiver
      - --enable-feature=native-histograms
      - --config.file=/etc/prometheus/prometheus.yml
    healthcheck:
      test: [ "CMD-SHELL" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - gilgoblin
    ports:
      - "9090:9090"
    depends_on:
      - gilgoblin-influxdb
    logging:
      driver: 'json-file'
      options:
        max-size: '50m'
    volumes:
      - ./benchmarks/prometheus:/etc/prometheus
    restart: unless-stopped

  gilgoblin-node-exporter:
    image: prom/node-exporter
    container_name: node-exporter
    healthcheck:
      test: [ "CMD-SHELL" ]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: 'json-file'
      options:
        max-size: '50m'
    depends_on:
      - gilgoblin-prometheus        
    networks:
      - gilgoblin
    ports:
      - "9100:9100"
    volumes:
      - ./benchmarks:/etc/node-exporter
    restart: unless-stopped

  gilgoblin-grafana:
    image: grafana/grafana
    container_name: grafana
    healthcheck:
      test: [ "CMD-SHELL" ]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: 'json-file'
      options:
        max-size: '50m'
    networks:
      - gilgoblin
    environment:
      - GF_AUTH_ANONYMOUS_ORG_ROLE=${GF_AUTH_ANONYMOUS_ORG_ROLE}
      - GF_AUTH_ANONYMOUS_ENABLED=${GF_AUTH_ANONYMOUS_ENABLED}
      - GF_AUTH_BASIC_ENABLED=${GF_AUTH_BASIC_ENABLED}
    ports:
      - "${PORT_GRAFANA}:3000"
    volumes:
      - ./benchmarks/grafana:/var/lib/grafana
    restart: unless-stopped

  ### Benchmarks ###

  # gilgoblin-k6-benchmarks:
  #   image: grafana/k6
  #   container_name: k6-benchmarks
  #   depends_on:
  #     - gilgoblin-database
  #     - gilgoblin-api
  #     - gilgoblin-prometheus
  #     - gilgoblin-influxdb
  #     - gilgoblin-grafana
  #   environment:
  #     - K6_PROMETHEUS_RW_SERVER_URL=http://host.docker.internal:9090/api/v1/write
  #     - K6_PROMETHEUS_RW_TREND_STATS=p(95),p(99),min,max
  #     - K6_PROMETHEUS_RW_TREND_AS_NATIVE_HISTOGRAM=true
  #   command: run -o experimental-prometheus-rw /scripts/crafts-benchmark.js --out influxdb=http://host.docker.internal:8086/gilgoblin_db
  #   networks:
  #     - gilgoblin
  #   ports:
  #     - "6565:6565"
  #   volumes:
  #     - ./benchmarks:/scripts
  #   restart: no

networks:
  gilgoblin: